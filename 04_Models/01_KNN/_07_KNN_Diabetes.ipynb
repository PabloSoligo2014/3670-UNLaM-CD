{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSLgqOSknCdK"
      },
      "source": [
        "# Vecinos más Cercanos (KNN) y Regresión Logística\n",
        "\n",
        "## Caso: Diabetes\n",
        "\n",
        "Vamos a utilizar un dataset que contiene datos de pacientes mujeres, llamado ***diabetes.csv***. El objetivo del dataset es predecir de forma diagnóstica si un paciente tiene diabetes o no, basándose en ciertas mediciones de diagnóstico.\n",
        "\n",
        "Los datos del dataset son:\n",
        "\n",
        "*   Pregnancies: Cantidad de embarazos\n",
        "*   Glucose: Concentración de glucosa en plasma a 2 horas, en prueba oral de tolerancia\n",
        "*   BloodPressure: Presión arterial diastólica (mm Hg)\n",
        "*   SkinThickness: Espesor del pliegue de la piel del tríceps (mm)\n",
        "*   Insulin:  Niveles de insulina en suero (micro U / ml)\n",
        "*   BMI: Índice de masa corporal (peso en kg / altura en m^2)\n",
        "*   DiabetesPedigreeFunction: Función pedigree de diabetes (representa la probabilidad de que contraiga la enfermedad extrapolando la historia de sus antepasados)\n",
        "*   Age: Edad de la paciente (en años)\n",
        "*   Outcome: Es el atributo clase a predecir, donde \"1\" indica con diabetes y \"0\" sin diabetes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M7wfK1DnCdP"
      },
      "source": [
        "## A. Análisis Exploratorio y Descriptivo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7hH3gmMnCdQ"
      },
      "source": [
        "# Importamos las librerías que necesitamos\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import pydotplus\n",
        "\n",
        "# Matriz de confusión\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Cargamos el dataset de diabetes\n",
        "df_diabetes = pd.read_csv('https://raw.githubusercontent.com/unlam-fcdin/UNLaM_FCDIN/master/diabetes.csv', sep = ',')\n",
        "df_diabetes.head(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nocMVGKOVFhr"
      },
      "source": [
        "Veamos los tipos de datos del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_l1OghrWOYW"
      },
      "source": [
        "df_diabetes.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnK8X5PcWc9K"
      },
      "source": [
        "Veamos el tamaño del dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEGyORyNWm3K"
      },
      "source": [
        "print(\"Tamaño del dataframe : {}\".format(df_diabetes.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nO_R62GXJw4"
      },
      "source": [
        "¿Cómo es la distribución de la variable clase Outcome?\n",
        "\n",
        "*Outcome* es la variable clase que vamos a predecir, la cual indica si el paciente es diabético o no. El **valor 1** significa que la persona es diabética mientas que el **valor 0** significa que no lo es."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxIr4RX6Yt0R"
      },
      "source": [
        "sns.countplot(x='Outcome', data=df_diabetes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC2aiW47Zbve"
      },
      "source": [
        "De acuerdo al gráfico vemos que hay más pacientes que no tienen diabetes, pero ¿cuántos exactamente?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX-eW6jjXg4a"
      },
      "source": [
        "df_diabetes.groupby('Outcome').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_tJmIIvXhiZ"
      },
      "source": [
        "Podemos identificar que de las 768 personas, 500 no son diabéticas (valor 0) y 268 sí lo son (valor 1).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoUIUI9XYNPB"
      },
      "source": [
        "Analicemos cómo afecta la posibilidad o no de tener diabetes, según los siguientes aspectos:\n",
        "\n",
        "*   Por la cantidad de embarazos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJM6hbAlnCdW"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la CANTIDAD DE EMBARAZOS de la paciente respecto a la CLASE\n",
        "plt.figure(figsize=(4, 8))\n",
        "s=sns.boxplot(x=\"Outcome\", y=\"Pregnancies\", data=df_diabetes)\n",
        "s.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlBep-k3eX4j"
      },
      "source": [
        "¿Se observa alguna relación respecto a la cantidad de embarazos entre las pacientes que tienen o no diabetes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOZPrp0bZBx2"
      },
      "source": [
        "\n",
        "*   Por edad de la paciente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svf097OQKYW8"
      },
      "source": [
        "plt.figure(figsize=(4, 8))\n",
        "s=sns.boxplot(x=\"Outcome\", y=\"Age\", data=df_diabetes)\n",
        "s.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt0CR7mEe44H"
      },
      "source": [
        "¿Se observa alguna relación respecto a la edad entre las pacientes que tienen o no diabetes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju1LQ6W8gX80"
      },
      "source": [
        "¿Cómo es la distribución de las edades de las pacientes?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3e0ikSrKYXC"
      },
      "source": [
        "# Construimos un gráfico de densidad\n",
        "plt.title('Age')\n",
        "sns.kdeplot(df_diabetes['Age'], shade=False) # shade indica si el gráfico es sombreado o no"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXkSxJdG_SNZ"
      },
      "source": [
        "# Veamos la media en valor absoluto\n",
        "print(\"Media: {}\".format(df_diabetes['Age'].mean()))\n",
        "print(\"Mediana: {}\".format(df_diabetes['Age'].median()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5MksijeZjhp"
      },
      "source": [
        "*   Por el índice de masa corporal (BMI)\n",
        "\n",
        "\n",
        "Tenemos los valores de referencia para entender la distribución de la variable:\n",
        "> ![Referencia](http://www.annacara.com/fotostratamientos/39foto01m.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncMqJ8pEKYW_"
      },
      "source": [
        "plt.figure(figsize=(4, 6))\n",
        "s=sns.boxplot(x=\"Outcome\", y=\"BMI\", data=df_diabetes)\n",
        "s.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjodftDDfz67"
      },
      "source": [
        "¿Se observa alguna relación respecto al índice de masa corporal (BMI) de las pacientes que tienen o no diabetes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2pNpNCPjoaa"
      },
      "source": [
        "## B. Preparación y Transformación de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w78wo3TN6_g"
      },
      "source": [
        "#### **Valores Faltantes**\n",
        "\n",
        "Comprobamos si alguno de los campos del dataset contiene valores faltantes o nulos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uChzqKcx1pkr"
      },
      "source": [
        "val_nulos = df_diabetes.isnull().sum()\n",
        "print(val_nulos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbEaUsVdacFm"
      },
      "source": [
        "#### **Valores Erróneos**\n",
        "\n",
        "Analicemos la información de los principales indicadores estadísticos del dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sP4bkirahe9"
      },
      "source": [
        "df_diabetes.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRsy33--W4ZB"
      },
      "source": [
        "Veamos gráficamente los atributos que tienen valores en cero (0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMxzBlSMXnlv"
      },
      "source": [
        "atributos_ceros = (df_diabetes == 0).sum(axis=0)\n",
        "atributos_ceros = pd.DataFrame(atributos_ceros, columns=['Cantidad de Ceros'])\n",
        "atributos_ceros = atributos_ceros.sort_values(by=['Cantidad de Ceros'], ascending=True)\n",
        "atributos_ceros.drop(['Outcome'], inplace = True)\n",
        "atributos_ceros.plot(kind='barh', figsize=(15,5), color='orange', grid=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43aHCcWtON4E"
      },
      "source": [
        "**Pregunta**: ¿Pueden tener valor cero (0) los siguientes atributos?\n",
        "\n",
        "* Glucose\n",
        "* BloodPressure\n",
        "* SkinThickness\n",
        "* Insulin\n",
        "* BMI\n",
        "\n",
        "En estas columnas, un valor en 0 no tiene sentido y, por lo tanto, indicaría un valor erróneo.\n",
        "\n",
        "Veamos cuántos valores así tiene cada atributo por cada etiqueta del atributo clase?\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egXQnqR07H9U"
      },
      "source": [
        "# Atributo Glucose\n",
        "print(\"Valores en cero: \", df_diabetes[df_diabetes.Glucose == 0].shape[0])\n",
        "df_diabetes[df_diabetes.Glucose == 0].groupby('Outcome').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsQkwD9J87g7"
      },
      "source": [
        "# Atributo BloodPressure\n",
        "print(\"Valores en cero: \", df_diabetes[df_diabetes.BloodPressure == 0].shape[0])\n",
        "df_diabetes[df_diabetes.BloodPressure == 0].groupby('Outcome').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKzQz69t9a_H"
      },
      "source": [
        "# Atributo SkinThickness\n",
        "print(\"Valores en cero: \", df_diabetes[df_diabetes.SkinThickness == 0].shape[0])\n",
        "df_diabetes[df_diabetes.SkinThickness == 0].groupby('Outcome').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bTM_q-w9o4a"
      },
      "source": [
        "# Atributo Insulin\n",
        "print(\"Valores en cero: \", df_diabetes[df_diabetes.Insulin == 0].shape[0])\n",
        "df_diabetes[df_diabetes.Insulin == 0].groupby('Outcome').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27n622nU91MZ"
      },
      "source": [
        "# Atributo BMI\n",
        "print(\"Valores en cero: \", df_diabetes[df_diabetes.BMI == 0].shape[0])\n",
        "df_diabetes[df_diabetes.BMI == 0].groupby('Outcome').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYxEO_yz-yEz"
      },
      "source": [
        "Hay varias formas de manejar valores erróneos:\n",
        "\n",
        "* **Eliminarlos**: esto no es posible en la mayoría de los casos porque significaría perder información valiosa. En el caso de los atributos \"SkinThickness\" e \"Insulin\" significan perder muchos datos. Pero podría funcionar para los atributos \"Glucose\", \"BloodPressure\" y \"BMI\".\n",
        "\n",
        "* **Imputarlos**: esto podría funcionar para algunos datos, por ejemplo usando la *media* o *mediana* de los valores. Tener cuidado de no generar valores muy distorsionados de los reales.\n",
        "\n",
        "* **Crear una nueva variable dicotómica iferror**: si se va a optar por imputar los valores o eliminar la columna, se puede crear una variable dictómica que analice si la variable original era correcta o no y ver como se comporta en el modelo.\n",
        "\n",
        "* **No usar los atributos**: si el atributo contiene muchos valores erróneos, podríamos evitar usarlos y ver cómo se comporta el modelo. No es posible saberlo de antemano.\n",
        "\n",
        "Veamos cómo es la distribución de los atributos con problemas para ver cuál estrategia elegir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPL6DuMEK1yl"
      },
      "source": [
        "# Construimos un histograma múltiple\n",
        "f, axes = plt.subplots(2, 3, figsize=(15, 10), sharex=False)\n",
        "\n",
        "sns.distplot(df_diabetes[\"Glucose\"], kde = False, color = \"skyblue\",ax=axes[0, 0]) # axes [fila,columna] indica la posición del histograma\n",
        "sns.distplot(df_diabetes[\"BloodPressure\"],kde = False, color = \"olive\", ax=axes[0, 1])\n",
        "sns.distplot(df_diabetes[\"SkinThickness\"],kde = False, color = \"red\", ax=axes[0, 2])\n",
        "sns.distplot(df_diabetes[\"Insulin\"],kde = False, color = \"gold\", ax=axes[1, 0])\n",
        "sns.distplot(df_diabetes[\"BMI\"],kde = False, color = \"teal\", ax=axes[1, 1])\n",
        "\n",
        "sns.distplot(df_diabetes[\"Pregnancies\"],kde = False, color = \"orange\", ax=axes[1, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUCLT5o_C-6z"
      },
      "source": [
        "#### **Valores Outliers**\n",
        "\n",
        "Analicemos la información de cada atributo para analizar posibles outliers.\n",
        "\n",
        "- **Pregnancies**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-471vsgDpuB"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"PREGNANCIES\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"Pregnancies\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l95Jo1dOSv2W"
      },
      "source": [
        "# Distribución de la variable \"PREGNANCIES\"\n",
        "print(df_diabetes['Pregnancies'].median())\n",
        "print(df_diabetes['Pregnancies'].std())\n",
        "sns.kdeplot(df_diabetes['Pregnancies'], shade=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tomc73y2H-uo"
      },
      "source": [
        "#print(df_diabetes['Pregnancies'].value_counts())\n",
        "\n",
        "# Obtenemos el valor límite superior para el outlier\n",
        "print(df_diabetes['Pregnancies'].mean())\n",
        "print(df_diabetes['Pregnancies'].std())\n",
        "outlier_superior = df_diabetes['Pregnancies'].mean() + 3*df_diabetes['Pregnancies'].std()   # +/-3 desvíos estándar es valor outlier\n",
        "print('Valor Outlier Superior: {:.2f}'.format(outlier_superior))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooYTfTMVq5zo"
      },
      "source": [
        "- **Glucose**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4IxzbnNrBxb"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"GLUCOSE\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"Glucose\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xmT7WOerKBd"
      },
      "source": [
        "Observamos que este atributo no tiene valores outliers.\n",
        "\n",
        "- **BloodPressure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDI77DVprZ9i"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"BLOODPRESSURE\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"BloodPressure\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lo1WawLrv0s"
      },
      "source": [
        "#print(df_diabetes['BloodPressure'].value_counts())\n",
        "\n",
        "# Obtenemos el valor límite para el outlier\n",
        "outlier_inferior = df_diabetes['BloodPressure'].mean() - 2.5*df_diabetes['BloodPressure'].std()   # -2.5 desvíos estándar es valor outlier inferior\n",
        "outlier_superior = df_diabetes['BloodPressure'].mean() + 2.5*df_diabetes['BloodPressure'].std()   # +2.5 desvíos estándar es valor outlier superior\n",
        "print('Valor Outlier Inferior: {:.2f} - Valor Outlier Superior {:.2f}'.format(outlier_inferior, outlier_superior))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDN5l_ORrlNz"
      },
      "source": [
        "# Distribución de la variable \"BloodPressure\"\n",
        "sns.kdeplot(df_diabetes['BloodPressure'], shade=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHIZWKwrsZcN"
      },
      "source": [
        "Del gráfico bloxpot vemos que el **límite inferior atípico es menor a 40**. El cálculo obtenido del outlier inferior aproximadamente el mismo, pero dejaría algunas observaciones con valores outlier. Por lo tanto, tomamos como límite inferior para la imputación el valor 40."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbODdPMJ81AD"
      },
      "source": [
        "- **SkinThickness**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvo9Y6BZ9FpJ"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"SKINTHICKNESS\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"SkinThickness\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m0B0-WT9TQ-"
      },
      "source": [
        "#print(df_diabetes['SkinThickness'].value_counts())\n",
        "\n",
        "# Obtenemos el valor límite para el outlier\n",
        "outlier_inferior = df_diabetes['SkinThickness'].mean() - 1.5*df_diabetes['SkinThickness'].std()   # -1.5 desvíos estándar es valor outlier inferior\n",
        "outlier_superior = df_diabetes['SkinThickness'].mean() + 1.5*df_diabetes['SkinThickness'].std()   # +1.5 desvíos estándar es valor outlier superior\n",
        "print('Valor Outlier Inferior: {:.2f} - Valor Outlier Superior {:.2f}'.format(outlier_inferior, outlier_superior))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rzr7ji3bPYP"
      },
      "source": [
        "# Distribución de la variable \"SkinThickness\"\n",
        "sns.kdeplot(df_diabetes['SkinThickness'], shade=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq86LAx0ADIc"
      },
      "source": [
        "- **Insulin**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4gliekOAPpq"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"INSULINE\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"Insulin\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlWxl1h7bosy"
      },
      "source": [
        "# Distribución de la variable \"Insulin\"\n",
        "sns.kdeplot(df_diabetes['Insulin'], shade=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFXT6Oz0HJ8h"
      },
      "source": [
        "Dado que hay observaciones con niveles de insulina por encima de los 250 micro U / ml, no vamos a considerarlas outliers, ya que pueden ser características significantes en pacientes con diabetes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsCDPfaHBpS8"
      },
      "source": [
        "- **BMI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSRGD7IgBzSV"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"BMI\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"BMI\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wfspEg3IYh7"
      },
      "source": [
        "#print(df_diabetes['BMI'].value_counts())\n",
        "\n",
        "# Obtenemos el valor límite para el outlier\n",
        "outlier_superior = df_diabetes['BMI'].mean() + 2.5*df_diabetes['BMI'].std()   # +2.5 desvíos estándar es valor outlier superior\n",
        "print('Valor Outlier Superior {:.2f}'.format(outlier_superior))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCmB6frvbwva"
      },
      "source": [
        "# Distribución de la variable \"BMI\"\n",
        "sns.kdeplot(df_diabetes['BMI'], shade=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnANsCUiD3Ka"
      },
      "source": [
        "- **DiabetesPedigreeFunction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgPhjS2VECEM"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"DiabetesPedigreeFunction\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"DiabetesPedigreeFunction\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7uWVC5AEQbv"
      },
      "source": [
        "#print(df_diabetes['DiabetesPedigreeFunction'].value_counts())\n",
        "\n",
        "# Obtenemos el valor límite para el outlier\n",
        "outlier_superior = df_diabetes['DiabetesPedigreeFunction'].mean() + 2*df_diabetes['DiabetesPedigreeFunction'].std()   # +2 desvíos estándar es valor outlier superior\n",
        "print('Valor Outlier Superior {:.2f}'.format(outlier_superior))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HnK-_AWb7nT"
      },
      "source": [
        "# Distribución de la variable \"DiabetesPedigreeFunction\"\n",
        "sns.kdeplot(df_diabetes['DiabetesPedigreeFunction'], shade=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0D31ZmBFHAZ"
      },
      "source": [
        "- **Age**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqF-sh6AJKWg"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"AGE\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"Age\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNNt_0EOq3r1"
      },
      "source": [
        "#### **Análisis de correlación de variables**\n",
        "\n",
        "Una matriz de correlación permite estudiar la relación lineal o comportamiento que puede existir entre dos o más variables.\n",
        "\n",
        "  - Correlación positiva: ocurre cuando una variable aumenta y la otra también.\n",
        "  - Correlación negativa: es cuando una variable aumenta y la otra disminuye.\n",
        "  - Sin correlación: no hay una relación aparente entre las variables.\n",
        "\n",
        "Calculamos la matriz de correlacion entre todas las variables del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm9AOI9OrOfv"
      },
      "source": [
        "# Matriz de correlación\n",
        "df_diabetes.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck8QIvj7u99v"
      },
      "source": [
        "La misma matriz podemos visualizarla mediante un **mapa de calor**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTcSPPUvu8wv"
      },
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "sns.heatmap(df_diabetes.corr(), annot=True, vmax=.7, cmap ='Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVd-poQBsDUB"
      },
      "source": [
        "Seleccionamos sólo la correlacion de la variable objetivo \"*Outcome*\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEZuW6husctm"
      },
      "source": [
        "df_diabetes_corr = df_diabetes.corr()[[\"Outcome\"]]*100\n",
        "df_diabetes_corr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPFvP5xLtX3H"
      },
      "source": [
        "Borramos la correlación de la variable objetivo consigo misma y ordenamos las variables predictoras de acuerdo a la correlación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4uppa5VtCHy"
      },
      "source": [
        "df_diabetes_corr = df_diabetes_corr.drop(\"Outcome\", axis=0)\n",
        "df_diabetes_corr = df_diabetes_corr.sort_values([\"Outcome\"], ascending=False) # ordenamos en forma descendente\n",
        "df_diabetes_corr = abs(df_diabetes_corr)\n",
        "df_diabetes_corr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aYkTgN0t7dI"
      },
      "source": [
        "Podemos visualizar lo mismo mediante un mapa de calor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K6VQkTht6xO"
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(df_diabetes_corr, robust=True, linewidths=.5, annot=True, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75KUYNEVqIhH"
      },
      "source": [
        "#### *Análisis preliminar*\n",
        "\n",
        "Del mapa de calor podemos observar que existe una correlación más alta entre las variables *Glucose*, *BMI*, *Age*, *Pregnancies* e *Insuline*  respecto a la posibilidad de que una paciente tenga diabetes.\n",
        "\n",
        "#### **Estandarización**\n",
        "\n",
        "Como los atributos tienen unidades y magnitudes diferentes, los normalizamos para mejorar la predicción. Aprovechando la estandarización, separamos del dataset las variables predictoras (X) y la variable clase (y)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaaMUSqyxUfe"
      },
      "source": [
        "# Aplicamos la estandarización\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler_X = StandardScaler(with_mean=True, with_std=True)\n",
        "scaler_X.fit(df_diabetes.drop([\"Outcome\"], axis = 1)) # entrenamos los valores quitandole la variable clase\n",
        "X_diabetes = pd.DataFrame(scaler_X.transform(df_diabetes.drop([\"Outcome\"],axis = 1),),\n",
        "                          columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness', 'Insulin',\n",
        "                                     'BMI','DiabetesPedigreeFunction','Age'])  # aplicamos la transformacion\n",
        "X_diabetes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnSury1I3Whh"
      },
      "source": [
        "**VEN ALGO INCORRECTO EN LA CELDA ANTERIOR???? Sino lo ven, vuelvan a verla.**\n",
        "<br>\n",
        "<br>\n",
        "Separamos ahora la variable clase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb9VJF3a3dfM"
      },
      "source": [
        "y_diabetes = df_diabetes[\"Outcome\"]\n",
        "y_diabetes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cei0R2OFnCdZ"
      },
      "source": [
        "## C. Construcción del modelo con Vecinos más Cercanos (KNN)\n",
        "\n",
        "En esta parte aprenderemos cómo aplicar un modelo KNN a problemas de clasificación. Para ello, utilizaremos el dataset de diabetes que ya tenemos preparado y construiremos un modelo para predecir si un paciente tiene diabetes o no.\n",
        "\n",
        "#### Referencia: [Documentación de Vecinos más Cercanos](https://scikit-learn.org/stable/modules/neighbors.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od0hHojvK9U2"
      },
      "source": [
        "#### **Partición del conjunto de datos**\n",
        "\n",
        "Dividimos el dataset original en dos conjuntos de datos:\n",
        "\n",
        "*  Conjunto de entrenamiento (70%)\n",
        "*  Conjunto de prueba (30%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjRyb5bqHLFJ"
      },
      "source": [
        "# Importamos la librería que necesitamos\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividimos X e y con train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_diabetes, y_diabetes, test_size=0.3, stratify = y_diabetes, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQYGPJ-VVg8t"
      },
      "source": [
        "El parámetro **stratify** permite que la proporción de valores de la clase **y** en la partición de la muestra se mantenga respecto a los valores originales. Por ejemplo, la variable \"y_diabetes\" en nuestro dataset es una variable categórica binaria con valores 0 y 1, si hay un 65% de ceros y un 35% de unos, *stratify = y_diabetes* se asegurará de que su división aleatoria mantenga la misma proporción de ceros y unos para la clase. Esto mismo podríamos aplicarlo en cualquier otro atributo que deseemos mantener la proporción de valores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dVFvA4jMecI"
      },
      "source": [
        "#### **Aplicación del algoritmo de vecinos más cercanos (KNN)**\n",
        "\n",
        "Una vez particionado los datos, parametrizamos la cantidad de vecinos K con los que queremos entrenar el algoritmo. Luego de entrenarlo para distintos valores de K, evaluamos sus resultados utilizando el conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKwWYjyunCdd"
      },
      "source": [
        "# Importamos la librería que necesitamos\n",
        "from sklearn.neighbors import KNeighborsClassifier # vecinos más cercanos para clasificación\n",
        "from sklearn.metrics import accuracy_score # métrica de evaluación\n",
        "\n",
        "test_scores = []\n",
        "\n",
        "# Creamos y entrenamos el algoritmo con 20 valores de K\n",
        "for k in range(1,20):\n",
        "  knn = KNeighborsClassifier(k)\n",
        "  knn.fit(X_train,y_train) # Creamos y entrenamos el clasificador knn\n",
        "\n",
        "  # Para cada valor de K, evaluamos la capacidad de clasificación con datos de prueba\n",
        "  y_pred = knn.predict(X_test)\n",
        "  test_scores.append(accuracy_score(y_test, y_pred)) # Agregamos los K resultados de evaluación"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn8SOFWLo8XZ"
      },
      "source": [
        "#### **Evaluación de los modelos**\n",
        "\n",
        "Para cada valor de K vecinos, veamos cuál fue la **exactitud** (Accuracy) obtenida por el modelo.\n",
        "\n",
        "Para ello, vamos a usar la función **enumerate()** que toma como argumento un objeto iterable y retorna otro cuyos elementos son tuplas de dos objetos: el primero indica la posición del elemento y el segundo, el elemento mismo. Por defecto, las posiciones de los elementos empiezan desde 0, pero puede indicarse el número de inicio como segundo argumento en la función enumerate()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhJHyelUpoSp"
      },
      "source": [
        "df_scores = pd.DataFrame([{\"k\":valor_k, \"score\":test_scores_k} for valor_k, test_scores_k in enumerate(test_scores, 1)])\n",
        "df_scores.head(5)\n",
        "plt.plot(df_scores[\"k\"], df_scores[\"score\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opEmrL-1qAIO"
      },
      "source": [
        "Queremos seleccionar el valor de K que obtuvo la mejor exactitud (accuracy) con la prueba del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6-sdbb4lkfB"
      },
      "source": [
        "# Buscamos la mayor exactitud y su valor K asociado, usando la funcion argmax (que empieza a contar de 0)\n",
        "k = (np.argmax(test_scores)+1)\n",
        "print('Exactitud (accuracy) del modelo: {:.2f} % - Mejor Valor de K = {}'.format(test_scores[k-1]*100, k))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVKlafHyH-ck"
      },
      "source": [
        "# Entrenamos el algoritmo con el mejor K\n",
        "knn = KNeighborsClassifier(k)\n",
        "knn.fit(X_train,y_train) # Entrenamos el clasificador"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekaPoxaHbBVX"
      },
      "source": [
        "#### **Matriz de confusión del modelo y errores de predicción**\n",
        "Utilizando el *conjunto de prueba*, verificamos la capacidad de predicción del modelo obtenido con el mejor K (k)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgCsLy6xIN-Q"
      },
      "source": [
        "# Calculamos y mostramos la matriz de confusión del modelo\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "confusion_matrix(y_test, y_pred_knn)\n",
        "pd.crosstab(y_test, y_pred_knn, rownames=['Real'], colnames=['Predicho'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT6qqb06UZpH"
      },
      "source": [
        "Es importante notar que para cualquier problema de clasificacion binaria (variable dicotómica) podemos considerar los siguientes terminos generales cuando medimos la capacidad predictiva de un modelo:\n",
        "- **True Positives  (TP)** = **38**  (Real=1 and Predicho=1)\n",
        "- **False Positives (FP)** = **12**  (Real=0 and Predicho=1)\n",
        "- **True Negative   (TN)** = **138** (Real=0 and Predicho=0)\n",
        "- **False Negative  (FN)** = **43**  (Real=1 and Predicho=0)\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Tenemos variadas metricas que nos interesan para medir la capacidad predictiva de un modelo de clasificación, entre ellas:\n",
        "- **Exactitud (Accuracy)** = TP+TN / (TP + TN + FP + FN)           \n",
        "- **Error de Predicción** = 1 - Exactitud\n",
        "- **Precisión** = TP / (TP + FP)\n",
        "- **Sensibilidad (Recall)** = TP / (TP + FN)\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Para este caso particular entonces tenemos:\n",
        "- Exactitud (Accuracy) = (38 + 138) / (38 + 138 + 12 + 43)  = **76.20%**\n",
        "- Error de Predicción = 1 - Exactitud = **23.80%**\n",
        "- Precisión = 38 / (38 + 12) = **76%**\n",
        "- Sensibilidad (Recall) = 38 / (38 + 43) = **46.9%**\n",
        "\n",
        "Podemos obtener un reporte con las mismas métricas del clasificador, utilizando la librería \"*classification_report*\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JjniTVMZ1tG"
      },
      "source": [
        "#Exactitud del modelo\n",
        "print('Exactitud (accuracy) del modelo: {:.2f} %'.format(accuracy_score(y_test, y_pred_knn)*100))\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Reporte del clasificador\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred_knn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJfna6qhnCd0"
      },
      "source": [
        "####**Optimización con GridSearchCV**\n",
        "\n",
        "Vamos a utilizar una técnica denominada **validación cruzada** o **cross-validation** para encontrar el mejor modelo de clasificación.\n",
        "\n",
        "> ![](https://raw.githubusercontent.com/unlam-fcdin/UNLaM_FCDIN/master/K-fold_cross_validation.jpg)\n",
        "\n",
        "Referencias:\n",
        "- http://scikit-learn.org/stable/modules/grid_search.html\n",
        "- https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada\n",
        "\n",
        "El clasificador de Vecinos más Cercanos (KNN) ofrece diversos hiper-parámetros para cada uno de los algoritmos que incluye. Vamos a utilizar como parámetro el número de vecinos K y la distancia \"minkowski\", que es la métrica de distancia por defecto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCVPIwPVnCd1"
      },
      "source": [
        "# Importamos la librería que necesitamos\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ALOW3DajhcR"
      },
      "source": [
        "Definimos los hiper-parámetros a utilizar para ajustar el modelo de clasificación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNb6h3_jnCd3"
      },
      "source": [
        "parametros = {'n_neighbors':np.arange(1,40)} # definimos 40 valores de K\n",
        "\n",
        "# Realizamos la búsqueda con Grid Search\n",
        "model = KNeighborsClassifier()\n",
        "gs = GridSearchCV(model, parametros, verbose=1 , n_jobs=-1, cv = 3)\n",
        "gs.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbOg9TaclPBh"
      },
      "source": [
        "El parámetro **cv** en el método **GridSearchCV** indica la cantidad de capas utilizadas para realizar validación cruzada. El valor por defecto es 5 capas.\n",
        "\n",
        "Mostramos los mejores resultados obtenidos a partir de los hiper-parámetros utilizados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBOt2B9HKYXx"
      },
      "source": [
        "print(\"Exactitud (Accuracy) en CV: {:.2f}%\".format(gs.best_score_ * 100))\n",
        "print(\"Parámetros del estimador: \" + str(gs.best_estimator_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsiimhoelxF_"
      },
      "source": [
        "El mejor resultado se obtuvo con **K = 19**, por lo tanto, este valor se toma para el modelo final.\n",
        "\n",
        "Utilizando el *conjunto de prueba* y los mejores hiper-parámetros seleccionados, verificamos la capacidad de predicción del modelo obtenido."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spJvCRrdnCd7"
      },
      "source": [
        "# Calculamos y mostramos la matriz de confusión del modelo\n",
        "y_pred_knn = gs.best_estimator_.predict(X_test)\n",
        "confusion_matrix(y_test, y_pred_knn)\n",
        "pd.crosstab(y_test, y_pred_knn, rownames=['Real'], colnames=['Predicho'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZQSbSMnKYX2"
      },
      "source": [
        "Es importante notar que para cualquier problema de clasificacion binaria (variable dicotómica) podemos considerar los siguientes terminos generales cuando medimos la capacidad predictiva de un modelo:\n",
        "- **True Positives  (TP)** = **XXX**  (Real=1 and Predicho=1)\n",
        "- **False Positives (FP)** = **XXX**  (Real=0 and Predicho=1)\n",
        "- **True Negative   (TN)** = **XXX** (Real=0 and Predicho=0)\n",
        "- **False Negative  (FN)** = **XXX**  (Real=1 and Predicho=0)\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Tenemos variadas metricas que nos interesan para medir la capacidad predictiva de un modelo de clasificación, entre ellas:\n",
        "- **Exactitud (Accuracy)** = TP+TN / (TP + TN + FP + FN)           \n",
        "- **Error de Predicción** = 1 - Exactitud\n",
        "- **Precisión** = TP / (TP + FP)\n",
        "- **Sensibilidad (Recall)** = TP / (TP + FN)\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Lo calculamos en clase:\n",
        "- Exactitud (Accuracy) = ( + ) / ( +  +  + )  = ****\n",
        "- Error de Predicción = 1 - Exactitud = ****\n",
        "- Precisión =  / ( + ) = ****\n",
        "- Sensibilidad (Recall) =  / ( + ) = ****\n",
        "\n",
        "Podemos obtener un reporte con las mismas métricas del clasificador, utilizando la librería \"*classification_report*\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMSm_FhRMOS-"
      },
      "source": [
        "#Exactitud del modelo\n",
        "print('Exactitud (accuracy) del modelo: {:.2f} %'.format(accuracy_score(y_test, y_pred_knn)*100))\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Reporte del clasificador\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred_knn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bksjaVdtmnNM"
      },
      "source": [
        "Fuera del accuracy, podemos ver que hay un trade-off entre la precisión y la sensibilidad (recall), ya que el modelo optimizado mejora en precisión pero empeora en sensibilidad (recall). Es decir, **cuando predice un positivo** lo hace con mejor efectividad, **pero cubre menos % del total de positivos** del set de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYkM29auB6ns"
      },
      "source": [
        "## E. *Otros enfoques: ¿Qué pasaría si no escalamos/imputamos el dataset?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjbz5-dKCd5Z"
      },
      "source": [
        "##### Volvemos a cargar el set de datos, lo normalizamos y dividimos X e y (entrenamiento y prueba)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2g7J9VTCFjK"
      },
      "source": [
        "# Antes volvemos a cargar el set de datos con una versión sin imputar, para comparar los resultados de ambas\n",
        "df_diabetes_si = pd.read_csv('https://raw.githubusercontent.com/unlam-fcdin/UNLaM_FCDIN/master/diabetes.csv', sep = ',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7116MM3yJ_XZ"
      },
      "source": [
        "#### **Opción 1**: Escalando las variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjAua8cJKVzR"
      },
      "source": [
        "# Escalamos las variables\n",
        "scaler_X = StandardScaler(with_mean=True, with_std=True)\n",
        "scaler_X.fit(df_diabetes_si.drop([\"Outcome\"],axis = 1)) # entrenamos los valores quitandole la variable clase\n",
        "X_diabetes_si = pd.DataFrame(scaler_X.transform(df_diabetes_si.drop([\"Outcome\"],axis = 1),),\n",
        "                          columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness', 'Insulin',\n",
        "                                     'BMI','DiabetesPedigreeFunction','Age'])  # aplicamos la transformacion\n",
        "y_diabetes_si = df_diabetes_si[\"Outcome\"]\n",
        "\n",
        "# Dividimos en entrenamiento y prueba\n",
        "X_train_si, X_test_si, y_train_si, y_test_si = train_test_split(X_diabetes_si, y_diabetes_si, test_size=0.3, stratify = y_diabetes_si, random_state=42)\n",
        "\n",
        "X_train_si.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL_pyukwKfhu"
      },
      "source": [
        "Probamos el **modelo KNN** (el mejor hasta ahora) sin imputar outliers ni valores erróneos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNPPe6C_KkyE"
      },
      "source": [
        "parametros = {'n_neighbors':np.arange(1,40)} # definimos 40 valores de K\n",
        "\n",
        "# Realizamos la búsqueda con Grid Search\n",
        "model = KNeighborsClassifier()\n",
        "gs = GridSearchCV(model, parametros, verbose=1 , n_jobs=-1, cv = 3)\n",
        "gs.fit(X_train_si, y_train_si)\n",
        "\n",
        "# Mostramos los resultados del mejor modelo\n",
        "print(\"-\"*100)\n",
        "print(\"Exactitud (Accuracy) en CV: {:.2f}%\".format(gs.best_score_ * 100))\n",
        "print(\"-\"*100)\n",
        "print(\"Parámetros del estimador: \" + str(gs.best_estimator_))\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Predecimos los casos de test para ver el accuracy\n",
        "y_pred = gs.best_estimator_.predict(X_test_si)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3-ifogeUZIo"
      },
      "source": [
        "Veamos los resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCgfbFyKUXwr"
      },
      "source": [
        "#Exactitud del modelo\n",
        "print('Exactitud (accuracy) del modelo: {:.2f} %'.format(accuracy_score(y_test_si, y_pred)*100))\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Reporte del clasificador\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_si,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8TSxfiTKWgX"
      },
      "source": [
        "#### **Opción 2**: Sin escalar las variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul8wnQxzKbr1"
      },
      "source": [
        "# Sin escalar las variables\n",
        "X_diabetes_si_se = df_diabetes_si.drop([\"Outcome\"],axis = 1)\n",
        "y_diabetes_si_se = df_diabetes_si[\"Outcome\"]\n",
        "\n",
        "# Dividimos en entrenamiento y prueba\n",
        "X_train_si_se, X_test_si_se, y_train_si_se, y_test_si_se = train_test_split(X_diabetes_si_se, y_diabetes_si_se, test_size=0.3, stratify = y_diabetes_si_se, random_state=42)\n",
        "\n",
        "X_train_si_se.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2izTd1DNQLkd"
      },
      "source": [
        "Ahora probamos el **modelo KNN** sin estandarizar los valores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vub817jYQKql"
      },
      "source": [
        "parametros = {'n_neighbors':np.arange(1,40)} # definimos 40 valores de K\n",
        "\n",
        "# Realizamos la búsqueda con Grid Search\n",
        "model = KNeighborsClassifier()\n",
        "gs = GridSearchCV(model, parametros, verbose=1 , n_jobs=-1, cv = 3)\n",
        "gs.fit(X_train_si_se, y_train_si_se)\n",
        "\n",
        "# Mostramos los resultados del mejor modelo\n",
        "print(\"-\"*100)\n",
        "print(\"Exactitud (Accuracy) en CV: {:.2f}%\".format(gs.best_score_ * 100))\n",
        "print(\"-\"*100)\n",
        "print(\"Parámetros del estimador: \" + str(gs.best_estimator_))\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Predecimos los casos de test para ver el accuracy\n",
        "y_pred = gs.best_estimator_.predict(X_test_si_se)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewxQ5kHyUoAx"
      },
      "source": [
        "Veamos los resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ldpMmOGUncx"
      },
      "source": [
        "#Exactitud del modelo\n",
        "print('Exactitud (accuracy) del modelo: {:.2f} %'.format(accuracy_score(y_test_si_se, y_pred)*100))\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Reporte del clasificador\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_si_se,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqjHk12qXmUa"
      },
      "source": [
        "### **CONCLUSIÓN FINAL**\n",
        "\n",
        "Pudimos ver, cómo influyó el **escalado** en el mejor de los modelos probados (KNN), el cual **incrementó sus puntos porcentuales de exactitud (accuracy)** cuando los datos fueron escalados. Esto era de esperarse porque es un modelo basado en distancias y, si las variables no tienen escalas similares, toman pesos distintos a la hora de calcular la distancia de cada observación con los K vecinos más cercanos.\n",
        "\n",
        "Asimismo, la **imputación** de valores erróneos y outliers contribuyó al incremento de la exactitud de este modelo KNN y, por consiguiente, a mejorar su capacidad predictiva.\n",
        "\n",
        "Es importante tener en claro cómo influyen los cambios que hacemos sobre los datos en la capacidad predictiva del modelo a generar, tanto para bien como para mal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti-NeRge_X-M"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}