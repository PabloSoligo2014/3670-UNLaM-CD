{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiSBXu1WPcp2"
      },
      "source": [
        "# Aprendizaje No Supervisado - Clustering Jerárquico y Reglas de Asociación\n",
        "### Librerías y configuraciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSDAnA5JWI2y"
      },
      "source": [
        "# Importamos las librerías necesarias\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import matplotlib\n",
        "import plotly.express as px\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "%matplotlib inline\n",
        "\n",
        "# Clustering Jerárquico\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "# Reglas de Asociación\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "from joblib import dump, load\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "rcParams['figure.figsize'] = (30,15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyotspYFKCRm"
      },
      "source": [
        "## 2. Caso: Análisis de Cesta de Mercado\n",
        "\n",
        "Para este caso, vamos a analizar un dataset con información del detalle de las compras realizadas en una cadena de Retail europea.\n",
        "\n",
        "El objetivo del caso es identificar los set de ítems que son frecuentes en una compra de supermercado, identificando patrones de ocurrencia simultánea entre distintos productos. Luego, seleccionaremos qué **reglas** consideramos de interés para el negocio en función de las métricas de *soporte, confianza y lift*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx7QDwWaOmXs"
      },
      "source": [
        "### 2.a) Lectura del set de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffSXPi6OK3k0"
      },
      "source": [
        "df = pd.read_excel('http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1e-Zi_OL9yL"
      },
      "source": [
        "### 2.b) Preparación de datos\n",
        "Para poder realizar un análisis de reglas de asociación, necesitamos el set de datos en un formato particular, dependiendo de la librería utilizada.\n",
        "\n",
        "Como en este caso estamos utilizando la librería *mlxtend*, necesitamos tener un registro por pedido (el numero de factura *InvoiceNo*) y en las columnas cada producto posible a incluir con un valor *True* o *False*, es decir, si lo incluye o no.\n",
        "\n",
        "Para esto, primero realizamos una limpieza inicial quitando caracteres especiales y luego generamos una tabla Pivot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fexDa8ZGLIEM"
      },
      "source": [
        "print(df.shape)\n",
        "\n",
        "# Comenzamos cortando los espacios vacíos y pasando todo a mayúsculas\n",
        "df['Description'] = df['Description'].str.strip().str.upper()\n",
        "\n",
        "# Quitamos los pedidos sin ID porque se deben a errores\n",
        "df.dropna(axis=0, subset=['InvoiceNo'], inplace=True)\n",
        "\n",
        "# Filtramos los pedidos donde la cantidad pedida sea <=0 ya que no son pedidos reales\n",
        "df['InvoiceNo'] = df['InvoiceNo'].astype('str')\n",
        "df = df[df['Quantity'] > 0]\n",
        "\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz7VOtownen_"
      },
      "source": [
        "Ahora, agrupamos por pedido/producto para aproximar la salida a lo que necesitamos cuando utilicemos el algoritmo \"apriori\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8En-i-4NnvV"
      },
      "source": [
        "# Quitamos los ítems DOTCOM POSTAGE y POSTAGE porque no son productos.\n",
        "# Llenamos con 0 los pedidos donde un producto no fué comprado\n",
        "df_group = (df.groupby(['InvoiceNo', 'Description'])['Quantity'].sum().unstack().reset_index().fillna(0).set_index('InvoiceNo').drop([\"POSTAGE\",\"DOTCOM POSTAGE\"], axis=1))\n",
        "\n",
        "# Seteamos True/False dependiendo de cada valor\n",
        "df_group = df_group.applymap(lambda x: True if x >0 else False)\n",
        "\n",
        "df_group"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A-K9kRASFoBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVC_3dQsPDVl"
      },
      "source": [
        "Vemos que tenemos un total de 20.136 pedidos con 4.058 productos distintos.\n",
        "\n",
        "En caso de tener una fuente de datos con un formato menos amigable, se pueden hacer uso de las librerías de transformación de datos propias del modulo *mlxtend.preprocessing*, como es el caso del transformador *TransactionEncoder*.\n",
        "\n",
        "#### Referencia: [Documentación de TransactionEncoder](http://rasbt.github.io/mlxtend/user_guide/preprocessing/TransactionEncoder/)\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjfdyDpcWOJO"
      },
      "source": [
        "### 2.c) Construcción del modelo\n",
        "Para construir un modelo de reglas de asociación necesitamos definir tres parámetros que van a influir directamente en el resultado obtenido y, sobre todo, en el tiempo de procesamiento. Estos parámetros son el *Soporte*, la *Confianza* y el *Lift*.\n",
        "\n",
        "#### **Definición de itemset frecuente**\n",
        "Antes de analizar las reglas de asociación entre todos los ítems, lo conveniente es definir un umbral mínimo de soporte, que permita considerar un *itemset* como **frecuente**. En nuestro caso, dado que tenemos 4058 productos consideramos un **umbral de soporte de 2.5%**.\n",
        "Una vez identificados todos los itemsets frecuentes, podemos avanzar a la detección de reglas de asociación sólo de estos items, optimizando de forma exponencial el tiempo de procesamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFSOqVzKM9z0"
      },
      "source": [
        "x = 0.025"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsFIPf5WTPyU"
      },
      "source": [
        "frequent_itemsets = apriori(df_group, min_support=x, use_colnames=True)\n",
        "frequent_itemsets.sort_values(by=\"support\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequent_itemsets.sample(1)"
      ],
      "metadata": {
        "id": "PkCsLSqLG2I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaGTLLHWYzSf"
      },
      "source": [
        "Vemos que el algoritmo obtuvo **220 itemsets más frecuentes**. Ahora debemos identificar qué cobertura queremos tener, y en función de eso definir el `umbral mínimo de soporte`.\n",
        "\n",
        "#### **Interpretación de la métrica Soporte**\n",
        "Para entender cómo se calcula la métrica de soporte, vamos a calcularlo de forma manual con un caso de ejemplo y ver como coincide con la métrica calculada.\n",
        "\n",
        "Vamos a tomar un itemset de un solo elemento (\"WHITE HANGING HEART T-LIGHT HOLDER\") y uno compuesto de dos elementos (\"CHARLOTTE BAG PINK POLKADOT\", \"RED RETROSPOT CHARLOTTE BAG\").\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuIDhbzZs0rz"
      },
      "source": [
        "# Tomamos el soporte del itemset ('RED RETROSPOT CHARLOTTE BAG')\n",
        "soporte_unq = frequent_itemsets[frequent_itemsets.itemsets == frozenset({'RED RETROSPOT CHARLOTTE BAG'})].support\n",
        "print(\"Soporte del itemset ('RED RETROSPOT CHARLOTTE BAG'): {}\".format(float(soporte_unq)))\n",
        "\n",
        "# Tomamos el soporte del itemset ('CHARLOTTE BAG PINK POLKADOT', 'RED RETROSPOT CHARLOTTE BAG')\n",
        "soporte_par = frequent_itemsets[frequent_itemsets.itemsets == frozenset({'CHARLOTTE BAG PINK POLKADOT', 'RED RETROSPOT CHARLOTTE BAG'})].support\n",
        "print(\"Soporte del itemset ('CHARLOTTE BAG PINK POLKADOT', 'RED RETROSPOT CHARLOTTE BAG'): {}\".format(float(soporte_par)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll3gdnGluTV-"
      },
      "source": [
        "Ahora veamos cuántos pedidos incluyen a cada itemset, y qué porcentaje del total de pedidos representan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Prv_uqSse-U"
      },
      "source": [
        "# Cantidad total de pedidos\n",
        "cn_total = df_group.shape[0]\n",
        "print(\"Cantidad Total de Pedidos: {}\".format(int(cn_total)))\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Comenzamos por el itemset simple  ('RED RETROSPOT CHARLOTTE BAG')\n",
        "cn_unq   = df_group[df_group['RED RETROSPOT CHARLOTTE BAG']==True].shape[0]\n",
        "\n",
        "print(\"Cantidad Pedidos que incluyen a ('RED RETROSPOT CHARLOTTE BAG'): {}\".format(int(cn_unq)))\n",
        "print(\"Soporte de ('RED RETROSPOT CHARLOTTE BAG'): {}\".format(float(cn_unq/cn_total)))\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Ahora lo mismo para el itemset complejo ('CHARLOTTE BAG PINK POLKADOT', 'RED RETROSPOT CHARLOTTE BAG')\n",
        "# Para este caso necesitamos que ambos items se encuentren en el mismo pedido simultaneamente\n",
        "cn_unq   = df_group[ ( df_group['RED RETROSPOT CHARLOTTE BAG']==True ) & ( df_group['CHARLOTTE BAG PINK POLKADOT']==True )].shape[0]\n",
        "\n",
        "print(\"Cantidad Pedidos que incluyen a ('CHARLOTTE BAG PINK POLKADOT', 'RED RETROSPOT CHARLOTTE BAG'): {}\".format(int(cn_unq)))\n",
        "print(\"Soporte de ('CHARLOTTE BAG PINK POLKADOT', 'RED RETROSPOT CHARLOTTE BAG'): {}\".format(float(cn_unq/cn_total)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYYt26r3wWDv"
      },
      "source": [
        "Podemos ver que coincide con lo calculado por el algoritmo de apriori. Esto nos sirve como referencia para entender qué umbral de soporte queremos utilizar en función de la cobertura esperada de las reglas obtenidas.\n",
        "\n",
        "Por ejemplo, teniendo **20.136 pedidos** y habiendo indicador un **soporte mínimo de 2,5% (0.025)**, nos aseguramos que cualquier itemset que analizaremos, será aplicable **por lo menos en 503 pedidos**.\n",
        "\n",
        "La forma general de calcular la cobertura es:\n",
        "```\n",
        "COBERTURA = CANTIDAD TOTAL DE IDS * SOPORTE\n",
        "```\n",
        "\n",
        "#### **Detección de Reglas de Asociación**\n",
        "\n",
        "Definidos los itemsets frecuentes, realizamos el análisis de reglas de asociación y comparamos distintas métricas, a fin de identificar cuáles son de utilidad para el negocio.\n",
        "\n",
        "En este caso vamos a usar como métrica LIFT y a considerar todas las reglas con LIFT mayor a 1, es decir, que tengan alguna variación con respecto a la distribución estándar de ocurrencia de productos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzKw0CgQWsF1"
      },
      "source": [
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
        "\n",
        "# Ordenamos por confianza de mayor a menor\n",
        "rules.sort_values(by=\"confidence\", ascending=False).head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hJjDwQL_Qn5"
      },
      "source": [
        "rules.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abjOhMB9xp1g"
      },
      "source": [
        "### 2.d) Interpretación del Soporte y la Confianza\n",
        "\n",
        "\n",
        "*   La métrica de **soporte** de una regla, explica qué *cobertura* tiene la regla detectada dentro de *total de observaciones*.\n",
        "\n",
        "*   La métrica de **confianza** de una regla, explica qué cobertura tiene la regla detectada sobre el *antecedente* en forma porcentual.\n",
        "\n",
        "Veamos un  ejemplo, si definimos una regla R1:\n",
        "```\n",
        "R1 : A -> B\n",
        "```\n",
        "siendo A el antecedente y B el consecuente.\n",
        "<br>\n",
        "- **Soporte R1**: Proporción de pedidos donde se encuentran A y B sobre el total de pedidos.\n",
        "\n",
        "  `Soporte R1:{A->B} =  (#Ocurrencias A^B)  / (#Observaciones) `\n",
        "<br>\n",
        "- **Confianza R1**: Proporción de pedidos donde se encuentran A y B sobre el total de pedidos donde se encuentra A:\n",
        "\n",
        "  `confianza R1:{A->B} = (#Ocurrencias A^B) / (#Ocurrencias A)  `\n",
        "<br>\n",
        "\n",
        "Verificamos la métrica calculada por el algoritmo para la regla de mayor `Confianza`:\n",
        "\n",
        "```\n",
        "Regla: ('PINK REGENCY TEACUP AND SAUCER','ROSES REGENCY TEACUP AND SAUCER') -> ('GREEN REGENCY TEACUP AND SAUCER')\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGNFeQfZZyWM"
      },
      "source": [
        "# Cantidad total de pedidos\n",
        "print(\"Cantidad Total de Pedidos: {}\".format(int(cn_total)))\n",
        "print(\" \"*100)\n",
        "print(\"-\"*100)\n",
        "print(\" \"*100)\n",
        "\n",
        "# Analizamos el soporte del antecedente  ('PINK REGENCY TEACUP AND SAUCER','ROSES REGENCY TEACUP AND SAUCER')\n",
        "cn_antecedente   = df_group[ ( df_group['PINK REGENCY TEACUP AND SAUCER']==True ) &\n",
        "                             ( df_group['ROSES REGENCY TEACUP AND SAUCER']==True )].shape[0]\n",
        "\n",
        "print(\"Cantidad Pedidos que incluyen a ('PINK REGENCY TEACUP AND SAUCER','ROSES REGENCY TEACUP AND SAUCER') : {}\".format(int(cn_antecedente)))\n",
        "print(\"Soporte del antecedente ('PINK REGENCY TEACUP AND SAUCER','ROSES REGENCY TEACUP AND SAUCER'): {}\".format(float(cn_antecedente/cn_total)))\n",
        "print(\" \"*100)\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Analizamos el soporte de la regla, es decir, la ocurrencia conjunta del consecuente y el antecedente\n",
        "cn_regla   = df_group[ ( df_group['PINK REGENCY TEACUP AND SAUCER']==True ) &\n",
        "                       ( df_group['ROSES REGENCY TEACUP AND SAUCER']==True ) &\n",
        "                       ( df_group['GREEN REGENCY TEACUP AND SAUCER']==True )].shape[0]\n",
        "print(\" \"*100)\n",
        "print(\"R: ('PINK REGENCY TEACUP AND SAUCER','ROSES REGENCY TEACUP AND SAUCER') -> ('GREEN REGENCY TEACUP AND SAUCER')\")\n",
        "print(\" \"*100)\n",
        "print(\"Cantidad Pedidos que cubre la regla : {}\".format(int(cn_regla)))\n",
        "print(\"Soporte de la regla: {}\".format(float(cn_regla/cn_total)))\n",
        "\n",
        "# Ahora calculamos la confianza, como la cantidad de pedidos donde ocurre la regla, sobre los pedidos del antecedente\n",
        "print(\"Confianza de la regla: {}\".format(float(cn_regla/cn_antecedente)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LUleSBq2CJR"
      },
      "source": [
        "Podemos concluir que **cerca del 3%** de los pedidos incluyen los productos **'PINK REGENCY TEACUP AND SAUCER', 'ROSES REGENCY TEACUP AND SAUCER'**, y dentro de esos pedidos **el 90%** también incluyen el producto **'GREEN REGENCY TEACUP AND SAUCER'**.\n",
        "\n",
        "Básicamente, estamos identificando las personas que compran juegos de té (Té Verde, Té Rosa, Té de rosas), si compró dos juegos de té, es muy problable que compre una tercera. Esto puede estar también relacionado con la típica promoción 3x2 o algo similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axN6x2D73xDC"
      },
      "source": [
        "### 2.e) Interpretación de la métrica LIFT\n",
        "\n",
        "El **LIFT** es una métrica que nos da una idea de qué tan relevante es el patrón detectado por una regla. La relevancia es medida comparando la confianza de la regla con el soporte del consecuente.\n",
        "\n",
        "  `LIFT R1:{A->B} = Confianza R1 / soporte{B}   `\n",
        "\n",
        "Entonces, si no existiera correlación de ocurrencia entre los itemsets esta relacion LIFT debería ser 1.\n",
        "\n",
        "En resumen, la interpretación del LIFT indica que:\n",
        "\n",
        " * Si el LIFT = 1, no existe relación de ocurrencia entre A y B.\n",
        "\n",
        " * Si el LIFT > 1, existe una relación positiva de ocurrencia entre A y B. Es más probable encontrar los productos juntos que por separado.\n",
        "\n",
        " * Si el LIFT < 1, existe una relación negativa de ocurrencia entre A y B, es más probable encontrarlos por separado que en conjunto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQcGbayI3UJ-"
      },
      "source": [
        "### 2.f) Explotación de Reglas Obtenidas\n",
        "\n",
        "Una vez generado el modelo, podemos seleccionar las reglas que más nos interesen ordenadas por Lift/Confianza/Soporte y también consultando aquellas que incluyan productos que resulten de interés comercial.\n",
        "\n",
        "Por ejemplo, queremos mejorar las ventas de cerveza Patagonia, podemos analizar qué productos suelen venderse en conjunto y a aquellos clientes que compraron alguno de esos productos y aún no compraron cerveza Patagonia, les hacemos una oferta pro-activa.\n",
        "\n",
        "Este tipo de acciones hoy en día se realizan con sistemas de recomendación más versátiles, pero en el fondo siguen embebiendo reglas que analizan la ocurrencia conjunta, ya sea de pedidos o de consumidores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDmCfSah09e0"
      },
      "source": [
        "# Reglas con soporte mayor a 3.5%, confianza > 70% y lift > 2\n",
        "rules[(rules.support > 0.035) & (rules.lift > 2) & (rules.confidence > 0.70)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkaqdnx3R7jP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}