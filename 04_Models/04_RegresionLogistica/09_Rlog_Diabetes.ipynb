{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSLgqOSknCdK"
      },
      "source": [
        "# Regresion Logistica (RegLog)\n",
        "\n",
        "## Caso: Diabetes\n",
        "\n",
        "Vamos a utilizar un dataset que contiene datos de pacientes mujeres, llamado ***diabetes.csv***. El objetivo del dataset es predecir de forma diagnóstica si un paciente tiene diabetes o no, basándose en ciertas mediciones de diagnóstico.\n",
        "\n",
        "Los datos del dataset son:\n",
        "\n",
        "*   Pregnancies: Cantidad de embarazos\n",
        "*   Glucose: Concentración de glucosa en plasma a 2 horas, en prueba oral de tolerancia\n",
        "*   BloodPressure: Presión arterial diastólica (mm Hg)\n",
        "*   SkinThickness: Espesor del pliegue de la piel del tríceps (mm)\n",
        "*   Insulin:  Niveles de insulina en suero (micro U / ml)\n",
        "*   BMI: Índice de masa corporal (peso en kg / altura en m^2)\n",
        "*   DiabetesPedigreeFunction: Función pedigree de diabetes (representa la probabilidad de que contraiga la enfermedad extrapolando la historia de sus antepasados)\n",
        "*   Age: Edad de la paciente (en años)\n",
        "*   Outcome: Es el atributo clase a predecir, donde \"1\" indica con diabetes y \"0\" sin diabetes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M7wfK1DnCdP"
      },
      "source": [
        "## A. Análisis Exploratorio y Descriptivo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7hH3gmMnCdQ"
      },
      "source": [
        "# Importamos las librerías que necesitamos\n",
        "\n",
        "# Instalamos skopt para hacer busqueda bayesiana de hiperparametros\n",
        "!pip install scikit-optimize\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn import metrics\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import pydotplus\n",
        "\n",
        "# Matriz de confusión\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Cargamos el dataset de diabetes\n",
        "df_diabetes = pd.read_csv('https://raw.githubusercontent.com/unlam-fcdin/UNLaM_FCDIN/master/diabetes.csv', sep = ',')\n",
        "df_diabetes.head(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nocMVGKOVFhr"
      },
      "source": [
        "Veamos los tipos de datos del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_l1OghrWOYW"
      },
      "source": [
        "df_diabetes.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnK8X5PcWc9K"
      },
      "source": [
        "Veamos el tamaño del dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEGyORyNWm3K"
      },
      "source": [
        "print(\"Tamaño del dataframe : {}\".format(df_diabetes.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nO_R62GXJw4"
      },
      "source": [
        "¿Cómo es la distribución de la variable clase Outcome?\n",
        "\n",
        "*Outcome* es la variable clase que vamos a predecir, la cual indica si el paciente es diabético o no. El **valor 1** significa que la persona es diabética mientas que el **valor 0** significa que no lo es."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxIr4RX6Yt0R"
      },
      "source": [
        "sns.countplot(x='Outcome', data=df_diabetes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC2aiW47Zbve"
      },
      "source": [
        "De acuerdo al gráfico vemos que hay más pacientes que no tienen diabetes, pero ¿cuántos exactamente?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX-eW6jjXg4a"
      },
      "source": [
        "df_diabetes.groupby('Outcome').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "268 / (500 + 268)"
      ],
      "metadata": {
        "id": "riVcQXjPBzpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_tJmIIvXhiZ"
      },
      "source": [
        "Podemos identificar que de las 768 personas, 500 no son diabéticas (valor 0) y 268 sí lo son (valor 1).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoUIUI9XYNPB"
      },
      "source": [
        "Analicemos cómo afecta la posibilidad o no de tener diabetes, según los siguientes aspectos:\n",
        "\n",
        "*   Por la cantidad de embarazos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJM6hbAlnCdW"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la CANTIDAD DE EMBARAZOS de la paciente respecto a la CLASE\n",
        "plt.figure(figsize=(4, 8))\n",
        "s=sns.boxplot(x=\"Outcome\", y=\"Pregnancies\", data=df_diabetes)\n",
        "s.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlBep-k3eX4j"
      },
      "source": [
        "¿Se observa alguna relación respecto a la cantidad de embarazos entre las pacientes que tienen o no diabetes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOZPrp0bZBx2"
      },
      "source": [
        "\n",
        "*   Por edad de la paciente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svf097OQKYW8"
      },
      "source": [
        "plt.figure(figsize=(4, 8))\n",
        "s=sns.boxplot(x=\"Outcome\", y=\"Age\", data=df_diabetes)\n",
        "s.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt0CR7mEe44H"
      },
      "source": [
        "¿Se observa alguna relación respecto a la edad entre las pacientes que tienen o no diabetes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju1LQ6W8gX80"
      },
      "source": [
        "¿Cómo es la distribución de las edades de las pacientes?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3e0ikSrKYXC"
      },
      "source": [
        "# Construimos un gráfico de densidad\n",
        "plt.title('Age')\n",
        "sns.kdeplot(df_diabetes['Age'], shade=False) # shade indica si el gráfico es sombreado o no"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXkSxJdG_SNZ"
      },
      "source": [
        "# Veamos la media en valor absoluto\n",
        "print(\"Media: {}\".format(df_diabetes['Age'].mean()))\n",
        "print(\"Mediana: {}\".format(df_diabetes['Age'].median()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5MksijeZjhp"
      },
      "source": [
        "*   Por el índice de masa corporal (BMI)\n",
        "\n",
        "\n",
        "Tenemos los valores de referencia para entender la distribución de la variable:\n",
        "> ![Referencia](http://www.annacara.com/fotostratamientos/39foto01m.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncMqJ8pEKYW_"
      },
      "source": [
        "plt.figure(figsize=(4, 6))\n",
        "s=sns.boxplot(x=\"Outcome\", y=\"BMI\", data=df_diabetes)\n",
        "s.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjodftDDfz67"
      },
      "source": [
        "¿Se observa alguna relación respecto al índice de masa corporal (BMI) de las pacientes que tienen o no diabetes?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zKYTXCk5UNZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2pNpNCPjoaa"
      },
      "source": [
        "## B. Preparación y Transformación de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w78wo3TN6_g"
      },
      "source": [
        "#### **Valores Faltantes**\n",
        "\n",
        "Comprobamos si alguno de los campos del dataset contiene valores faltantes o nulos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uChzqKcx1pkr"
      },
      "source": [
        "val_nulos = df_diabetes.isnull().sum()\n",
        "print(val_nulos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbEaUsVdacFm"
      },
      "source": [
        "#### **Valores Erróneos**\n",
        "\n",
        "Analicemos la información de los principales indicadores estadísticos del dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sP4bkirahe9"
      },
      "source": [
        "df_diabetes.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRsy33--W4ZB"
      },
      "source": [
        "Veamos gráficamente los atributos que tienen valores en cero (0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMxzBlSMXnlv"
      },
      "source": [
        "atributos_ceros = (df_diabetes == 0).sum(axis=0)\n",
        "atributos_ceros = pd.DataFrame(atributos_ceros, columns=['Cantidad de Ceros'])\n",
        "atributos_ceros = atributos_ceros.sort_values(by=['Cantidad de Ceros'], ascending=True)\n",
        "atributos_ceros.drop(['Outcome'], inplace = True)\n",
        "atributos_ceros.plot(kind='barh', figsize=(15,5), color='orange', grid=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43aHCcWtON4E"
      },
      "source": [
        "**Pregunta**: ¿Pueden tener valor cero (0) los siguientes atributos?\n",
        "\n",
        "* Glucose\n",
        "* BloodPressure\n",
        "* SkinThickness\n",
        "* Insulin\n",
        "* BMI\n",
        "\n",
        "En estas columnas, un valor en 0 no tiene sentido y, por lo tanto, indicaría un valor erróneo.\n",
        "\n",
        "Veamos cuántos valores así tiene cada atributo por cada etiqueta del atributo clase?\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egXQnqR07H9U"
      },
      "source": [
        "# Atributo Glucose\n",
        "print(\"Valores en cero: \", df_diabetes[df_diabetes.Glucose == 0].shape[0])\n",
        "df_diabetes[df_diabetes.Glucose == 0].groupby('Outcome').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsQkwD9J87g7"
      },
      "source": [
        "# Atributo BloodPressure\n",
        "print(\"Valores en cero: \", df_diabetes[df_diabetes.BloodPressure == 0].shape[0])\n",
        "df_diabetes[df_diabetes.BloodPressure == 0].groupby('Outcome').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKzQz69t9a_H"
      },
      "source": [
        "# Atributo SkinThickness\n",
        "print(\"Valores en cero: \", df_diabetes[df_diabetes.SkinThickness == 0].shape[0])\n",
        "df_diabetes[df_diabetes.SkinThickness == 0].groupby('Outcome').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bTM_q-w9o4a"
      },
      "source": [
        "# Atributo Insulin\n",
        "print(\"Valores en cero: \", df_diabetes[df_diabetes.Insulin == 0].shape[0])\n",
        "df_diabetes[df_diabetes.Insulin == 0].groupby('Outcome').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27n622nU91MZ"
      },
      "source": [
        "# Atributo BMI\n",
        "print(\"Valores en cero: \", df_diabetes[df_diabetes.BMI == 0].shape[0])\n",
        "df_diabetes[df_diabetes.BMI == 0].groupby('Outcome').size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYxEO_yz-yEz"
      },
      "source": [
        "Hay varias formas de manejar valores erróneos:\n",
        "\n",
        "* **Eliminarlos**: esto no es posible en la mayoría de los casos porque significaría perder información valiosa. En el caso de los atributos \"SkinThickness\" e \"Insulin\" significan perder muchos datos. Pero podría funcionar para los atributos \"Glucose\", \"BloodPressure\" y \"BMI\".\n",
        "\n",
        "* **Imputarlos**: esto podría funcionar para algunos datos, por ejemplo usando la *media* o *mediana* de los valores. Tener cuidado de no generar valores muy distorsionados de los reales.\n",
        "\n",
        "* **Crear una nueva variable dicotómica iferror**: si se va a optar por imputar los valores o eliminar la columna, se puede crear una variable dictómica que analice si la variable original era correcta o no y ver como se comporta en el modelo.\n",
        "\n",
        "* **No usar los atributos**: si el atributo contiene muchos valores erróneos, podríamos evitar usarlos y ver cómo se comporta el modelo. No es posible saberlo de antemano.\n",
        "\n",
        "Veamos cómo es la distribución de los atributos con problemas para ver cuál estrategia elegir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPL6DuMEK1yl"
      },
      "source": [
        "# Construimos un histograma múltiple\n",
        "f, axes = plt.subplots(2, 3, figsize=(15, 10), sharex=False)\n",
        "\n",
        "sns.distplot(df_diabetes[\"Glucose\"], kde = False, color = \"skyblue\",ax=axes[0, 0]) # axes [fila,columna] indica la posición del histograma\n",
        "sns.distplot(df_diabetes[\"BloodPressure\"],kde = False, color = \"olive\", ax=axes[0, 1])\n",
        "sns.distplot(df_diabetes[\"SkinThickness\"],kde = False, color = \"red\", ax=axes[0, 2])\n",
        "sns.distplot(df_diabetes[\"Insulin\"],kde = False, color = \"gold\", ax=axes[1, 0])\n",
        "sns.distplot(df_diabetes[\"BMI\"],kde = False, color = \"teal\", ax=axes[1, 1])\n",
        "\n",
        "sns.distplot(df_diabetes[\"Pregnancies\"],kde = False, color = \"orange\", ax=axes[1, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUCLT5o_C-6z"
      },
      "source": [
        "#### **Valores Outliers**\n",
        "\n",
        "Analicemos la información de cada atributo para analizar posibles outliers.\n",
        "\n",
        "- **Pregnancies**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-471vsgDpuB"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"PREGNANCIES\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"Pregnancies\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l95Jo1dOSv2W"
      },
      "source": [
        "# Distribución de la variable \"PREGNANCIES\"\n",
        "print(df_diabetes['Pregnancies'].median())\n",
        "print(df_diabetes['Pregnancies'].std())\n",
        "sns.kdeplot(df_diabetes['Pregnancies'], shade=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tomc73y2H-uo"
      },
      "source": [
        "#print(df_diabetes['Pregnancies'].value_counts())\n",
        "\n",
        "# Obtenemos el valor límite superior para el outlier\n",
        "print(df_diabetes['Pregnancies'].mean())\n",
        "print(df_diabetes['Pregnancies'].std())\n",
        "outlier_superior = df_diabetes['Pregnancies'].mean() + 3*df_diabetes['Pregnancies'].std()   # +/-3 desvíos estándar es valor outlier\n",
        "print('Valor Outlier Superior: {:.2f}'.format(outlier_superior))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooYTfTMVq5zo"
      },
      "source": [
        "- **Glucose**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4IxzbnNrBxb"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"GLUCOSE\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"Glucose\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xmT7WOerKBd"
      },
      "source": [
        "Observamos que este atributo no tiene valores outliers.\n",
        "\n",
        "- **BloodPressure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDI77DVprZ9i"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"BLOODPRESSURE\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"BloodPressure\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lo1WawLrv0s"
      },
      "source": [
        "#print(df_diabetes['BloodPressure'].value_counts())\n",
        "\n",
        "# Obtenemos el valor límite para el outlier\n",
        "outlier_inferior = df_diabetes['BloodPressure'].mean() - 1*df_diabetes['BloodPressure'].std()   # -2.5 desvíos estándar es valor outlier inferior\n",
        "outlier_superior = df_diabetes['BloodPressure'].mean() + 1*df_diabetes['BloodPressure'].std()   # +2.5 desvíos estándar es valor outlier superior\n",
        "print('Valor Outlier Inferior: {:.2f} - Valor Outlier Superior {:.2f}'.format(outlier_inferior, outlier_superior))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDN5l_ORrlNz"
      },
      "source": [
        "# Distribución de la variable \"BloodPressure\"\n",
        "sns.kdeplot(df_diabetes['BloodPressure'], shade=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHIZWKwrsZcN"
      },
      "source": [
        "Del gráfico bloxpot vemos que el **límite inferior atípico es menor a 40**. El cálculo obtenido del outlier inferior aproximadamente el mismo, pero dejaría algunas observaciones con valores outlier. Por lo tanto, tomamos como límite inferior para la imputación el valor 40."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbODdPMJ81AD"
      },
      "source": [
        "- **SkinThickness**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvo9Y6BZ9FpJ"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"SKINTHICKNESS\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"SkinThickness\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m0B0-WT9TQ-"
      },
      "source": [
        "#print(df_diabetes['SkinThickness'].value_counts())\n",
        "\n",
        "# Obtenemos el valor límite para el outlier\n",
        "outlier_inferior = df_diabetes['SkinThickness'].mean() - 1.5*df_diabetes['SkinThickness'].std()   # -1.5 desvíos estándar es valor outlier inferior\n",
        "outlier_superior = df_diabetes['SkinThickness'].mean() + 1.5*df_diabetes['SkinThickness'].std()   # +1.5 desvíos estándar es valor outlier superior\n",
        "print('Valor Outlier Inferior: {:.2f} - Valor Outlier Superior {:.2f}'.format(outlier_inferior, outlier_superior))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rzr7ji3bPYP"
      },
      "source": [
        "# Distribución de la variable \"SkinThickness\"\n",
        "sns.kdeplot(df_diabetes['SkinThickness'], shade=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq86LAx0ADIc"
      },
      "source": [
        "- **Insulin**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4gliekOAPpq"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"INSULINE\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"Insulin\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlWxl1h7bosy"
      },
      "source": [
        "# Distribución de la variable \"Insulin\"\n",
        "sns.kdeplot(df_diabetes['Insulin'], shade=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFXT6Oz0HJ8h"
      },
      "source": [
        "Dado que hay observaciones con niveles de insulina por encima de los 250 micro U / ml, no vamos a considerarlas outliers, ya que pueden ser características significantes en pacientes con diabetes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsCDPfaHBpS8"
      },
      "source": [
        "- **BMI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSRGD7IgBzSV"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"BMI\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"BMI\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wfspEg3IYh7"
      },
      "source": [
        "#print(df_diabetes['BMI'].value_counts())\n",
        "\n",
        "# Obtenemos el valor límite para el outlier\n",
        "outlier_superior = df_diabetes['BMI'].mean() + 2.5*df_diabetes['BMI'].std()   # +2.5 desvíos estándar es valor outlier superior\n",
        "print('Valor Outlier Superior {:.2f}'.format(outlier_superior))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCmB6frvbwva"
      },
      "source": [
        "# Distribución de la variable \"BMI\"\n",
        "sns.kdeplot(df_diabetes['BMI'], shade=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnANsCUiD3Ka"
      },
      "source": [
        "- **DiabetesPedigreeFunction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgPhjS2VECEM"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"DiabetesPedigreeFunction\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"DiabetesPedigreeFunction\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7uWVC5AEQbv"
      },
      "source": [
        "#print(df_diabetes['DiabetesPedigreeFunction'].value_counts())\n",
        "\n",
        "# Obtenemos el valor límite para el outlier\n",
        "outlier_superior = df_diabetes['DiabetesPedigreeFunction'].mean() + 2*df_diabetes['DiabetesPedigreeFunction'].std()   # +2 desvíos estándar es valor outlier superior\n",
        "print('Valor Outlier Superior {:.2f}'.format(outlier_superior))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HnK-_AWb7nT"
      },
      "source": [
        "# Distribución de la variable \"DiabetesPedigreeFunction\"\n",
        "sns.kdeplot(df_diabetes['DiabetesPedigreeFunction'], shade=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0D31ZmBFHAZ"
      },
      "source": [
        "- **Age**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqF-sh6AJKWg"
      },
      "source": [
        "# Creamos un gráfico boxplot para analizar la variable \"AGE\"\n",
        "plt.figure(figsize=(10, 3))\n",
        "sns.boxplot(x=\"Age\", data=df_diabetes, orient = 'h', palette=\"Set2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNNt_0EOq3r1"
      },
      "source": [
        "#### **Análisis de correlación de variables**\n",
        "\n",
        "Una matriz de correlación permite estudiar la relación lineal o comportamiento que puede existir entre dos o más variables.\n",
        "\n",
        "  - Correlación positiva: ocurre cuando una variable aumenta y la otra también.\n",
        "  - Correlación negativa: es cuando una variable aumenta y la otra disminuye.\n",
        "  - Sin correlación: no hay una relación aparente entre las variables.\n",
        "\n",
        "Calculamos la matriz de correlacion entre todas las variables del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm9AOI9OrOfv"
      },
      "source": [
        "# Matriz de correlación\n",
        "df_diabetes.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck8QIvj7u99v"
      },
      "source": [
        "La misma matriz podemos visualizarla mediante un **mapa de calor**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTcSPPUvu8wv"
      },
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "sns.heatmap(df_diabetes.corr(), annot=True, vmax=.7, cmap ='Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVd-poQBsDUB"
      },
      "source": [
        "Seleccionamos sólo la correlacion de la variable objetivo \"*Outcome*\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEZuW6husctm"
      },
      "source": [
        "df_diabetes_corr = df_diabetes.corr()[[\"Outcome\"]]*100\n",
        "df_diabetes_corr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPFvP5xLtX3H"
      },
      "source": [
        "Borramos la correlación de la variable objetivo consigo misma y ordenamos las variables predictoras de acuerdo a la correlación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4uppa5VtCHy"
      },
      "source": [
        "df_diabetes_corr = df_diabetes_corr.drop(\"Outcome\", axis=0)\n",
        "df_diabetes_corr = df_diabetes_corr.sort_values([\"Outcome\"], ascending=False) # ordenamos en forma descendente\n",
        "df_diabetes_corr = abs(df_diabetes_corr)\n",
        "df_diabetes_corr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aYkTgN0t7dI"
      },
      "source": [
        "Podemos visualizar lo mismo mediante un mapa de calor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K6VQkTht6xO"
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(df_diabetes_corr, robust=True, linewidths=.5, annot=True, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75KUYNEVqIhH"
      },
      "source": [
        "#### *Análisis preliminar*\n",
        "\n",
        "Del mapa de calor podemos observar que existe una correlación más alta entre las variables *Glucose*, *BMI*, *Age*, *Pregnancies* e *Insuline*  respecto a la posibilidad de que una paciente tenga diabetes.\n",
        "\n",
        "#### **Estandarización**\n",
        "\n",
        "Como los atributos tienen unidades y magnitudes diferentes, los normalizamos para mejorar la predicción. Aprovechando la estandarización, separamos del dataset las variables predictoras (X) y la variable clase (y)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaaMUSqyxUfe"
      },
      "source": [
        "# Aplicamos la estandarización\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler_X = StandardScaler(with_mean=True, with_std=True)\n",
        "scaler_X.fit(df_diabetes.drop([\"Outcome\"], axis = 1)) # entrenamos los valores quitandole la variable clase\n",
        "X_diabetes = pd.DataFrame(scaler_X.transform(df_diabetes.drop([\"Outcome\"],axis = 1),),\n",
        "                          columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness', 'Insulin',\n",
        "                                     'BMI','DiabetesPedigreeFunction','Age'])  # aplicamos la transformacion\n",
        "X_diabetes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnSury1I3Whh"
      },
      "source": [
        "**VEN ALGO INCORRECTO EN LA CELDA ANTERIOR???? Sino lo ven, vuelvan a verla.**\n",
        "<br>\n",
        "<br>\n",
        "Separamos ahora la variable clase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb9VJF3a3dfM"
      },
      "source": [
        "y_diabetes = df_diabetes[\"Outcome\"]\n",
        "y_diabetes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D. Partición del conjunto de datos\n",
        "\n",
        "Dividimos el dataset original en dos conjuntos de datos:\n",
        "\n",
        "*  Conjunto de entrenamiento (70%)\n",
        "*  Conjunto de prueba (30%)"
      ],
      "metadata": {
        "id": "ehvz6QHTVTg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos la librería que necesitamos\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividimos X e y con train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_diabetes, y_diabetes, test_size=0.3, stratify = y_diabetes, random_state=42)"
      ],
      "metadata": {
        "id": "O9RYRD-KVZUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## E. Construcción del modelo con Regresión Logística\n",
        "\n",
        "En esta parte aprenderemos cómo aplicar un modelo de Regresión Logística en problemas de clasificación.\n",
        "\n",
        "#### Referencia: [Documentación de Regresión Logística](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
        "\n",
        "#### **Aplicación del algoritmo**\n",
        "\n",
        "Como vimos, el algoritmo de regresión logística es apropiado para realizar predicciones cuando la variable clase es binaria. Cuando la variable a predecir es \"multi clase\", el algoritmo puede usar un esquema \"uno vs el resto\" para mantener una relación binaria.\n",
        "\n",
        "Con los datos ya particionados, procedemos a entrenar el modelo y a evaluar los resultados utilizando el conjunto de prueba."
      ],
      "metadata": {
        "id": "Xm1xpDobTENB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos la librería que necesitamos\n",
        "from sklearn.linear_model import LogisticRegression # regresión logística para clasificación\n",
        "from sklearn.metrics import accuracy_score # métrica de evaluación\n",
        "\n",
        "RegLog = LogisticRegression()\n",
        "RegLog.fit(X_train,y_train) # Creamos y entrenamos el clasificador de regresión logística"
      ],
      "metadata": {
        "id": "s1wxxmuiTLR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos qué peso tiene cada variable en la regresión.\n",
        "Este análisis lo realizamos a través de los coeficientes asignados en la recta de regresión a cada variable, cuanto mayor el coeficiente, mayor el peso en la recta.\n",
        "Esto es similar al \"feature importance\" en los árboles de decisión."
      ],
      "metadata": {
        "id": "5Bv9QddMTOW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'Atributo':X_train.columns,\n",
        "              'importancia':abs(RegLog.coef_[0])}).sort_values('importancia', ascending=False).head(10)"
      ],
      "metadata": {
        "id": "RBa72kXKTRo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que las variables con mayor correlación numérica, también salieron importantes en la regresión, pero no en el mismo orden.\n",
        "¿Por qué? ¿Qué pasa si quitamos alguna variable importante y recalculamos el modelo? ¿Mejora o empeora?"
      ],
      "metadata": {
        "id": "eYK6ma_TTV3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.describe()"
      ],
      "metadata": {
        "id": "0M5DTuawTWqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Evaluación del modelo y Matriz de Confusión**\n",
        "\n",
        "Con el modelo ya entrenado, utilizamos el *conjunto de prueba* para verificar su capacidad de predicción."
      ],
      "metadata": {
        "id": "yQnzuGtqTlEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos y mostramos la matriz de confusión del modelo\n",
        "y_pred_RLog = RegLog.predict(X_test)\n",
        "confusion_matrix(y_test, y_pred_RLog)\n",
        "pd.crosstab(y_test, y_pred_RLog, rownames=['Real'], colnames=['Predicho'])"
      ],
      "metadata": {
        "id": "0ZmMNSO8Tl5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos cuál fue la **exactitud** (Accuracy) obtenida por el modelo."
      ],
      "metadata": {
        "id": "O-OvZwkITmJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exactitud del modelo\n",
        "print('Exactitud (accuracy) del modelo: {:.2f} %'.format(accuracy_score(y_test, y_pred_RLog)*100))\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Reporte del clasificador\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred_RLog))"
      ],
      "metadata": {
        "id": "oq1N9z9bTfpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Optimización con BayesSearchCV**\n",
        "\n",
        "Nuevamente utilizamos la técnica de **validación cruzada** o **cross-validation** para encontrar el mejor modelo de clasificación.\n",
        "El algoritmo de búsqueda Bayesiana es una mejora sobre los metodos standards GridSearch (probar todo) y RandomSearch (prueba aleatoria).\n",
        "<br><br>\n",
        "En este caso el algoritmo hace una busqueda de los posibles hot-zones donde la metrica definida (en este caso AUC score) \"crece\" y trata de hacer una búsqueda enfocada en mejorar el score y descartar pruebas innecesarias hasta un punto de convergencia y/o superar el maximo de iteraciones definidos `n_iter`."
      ],
      "metadata": {
        "id": "QMeYJf0hT3tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parametros = {'penalty': ['l2'],\n",
        "               'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "# Realizamos la búsqueda con BayesSearchCV\n",
        "modeloRL = LogisticRegression()\n",
        "gs = BayesSearchCV(modeloRL, parametros, scoring='precision', verbose=0 , n_jobs=-1, cv = 3, random_state=3, n_iter=50)\n",
        "gs.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "B71QpelBUOuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostramos los mejores resultados obtenidos a partir de los hiper-parámetros utilizados."
      ],
      "metadata": {
        "id": "FMRanZBeUc-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Exactitud (Accuracy) dentro del CV: {:.2f}%\".format(gs.best_score_ * 100))\n",
        "print(\"Parámetros del estimador: \" + str(gs.best_estimator_))"
      ],
      "metadata": {
        "id": "0a1MxEnLUduR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predigo los valores\n",
        "y_pred_RLog = gs.best_estimator_.predict(X_test)\n",
        "\n",
        "#Exactitud del modelo\n",
        "print('Exactitud (accuracy) del modelo: {:.2f} %'.format(accuracy_score(y_test, y_pred_RLog)*100))\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Reporte del clasificador\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred_RLog))"
      ],
      "metadata": {
        "id": "EVf8VoEUUiWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYkM29auB6ns"
      },
      "source": [
        "## F. *Otros enfoques: ¿Qué pasaría si no escalamos/imputamos el dataset?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjbz5-dKCd5Z"
      },
      "source": [
        "##### Volvemos a cargar el set de datos, lo normalizamos y dividimos X e y (entrenamiento y prueba)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2g7J9VTCFjK"
      },
      "source": [
        "# Antes volvemos a cargar el set de datos con una versión sin imputar, para comparar los resultados de ambas\n",
        "df_diabetes_si = pd.read_csv('https://raw.githubusercontent.com/unlam-fcdin/UNLaM_FCDIN/master/diabetes.csv', sep = ',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7116MM3yJ_XZ"
      },
      "source": [
        "#### **Opción 1**: Escalando las variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjAua8cJKVzR"
      },
      "source": [
        "# Escalamos las variables\n",
        "scaler_X = StandardScaler(with_mean=True, with_std=True)\n",
        "scaler_X.fit(df_diabetes_si.drop([\"Outcome\"],axis = 1)) # entrenamos los valores quitandole la variable clase\n",
        "X_diabetes_si = pd.DataFrame(scaler_X.transform(df_diabetes_si.drop([\"Outcome\"],axis = 1),),\n",
        "                          columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness', 'Insulin',\n",
        "                                     'BMI','DiabetesPedigreeFunction','Age'])  # aplicamos la transformacion\n",
        "y_diabetes_si = df_diabetes_si[\"Outcome\"]\n",
        "\n",
        "# Dividimos en entrenamiento y prueba\n",
        "X_train_si, X_test_si, y_train_si, y_test_si = train_test_split(X_diabetes_si, y_diabetes_si, test_size=0.3, stratify = y_diabetes_si, random_state=42)\n",
        "\n",
        "X_train_si.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL_pyukwKfhu"
      },
      "source": [
        "Probamos el **modelo KNN** (el mejor hasta ahora) sin imputar outliers ni valores erróneos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNPPe6C_KkyE"
      },
      "source": [
        "parametros = {'penalty': ['l2'],\n",
        "               'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "# Realizamos la búsqueda con Bayes Search\n",
        "modeloRL = LogisticRegression()\n",
        "gs = BayesSearchCV(modeloRL, parametros, scoring='roc_auc', verbose=0 , n_jobs=-1, cv = 3, random_state=3, n_iter=50)\n",
        "gs.fit(X_train_si, y_train_si)\n",
        "\n",
        "# Mostramos los resultados del mejor modelo\n",
        "print(\"-\"*100)\n",
        "print(\"AUC en CV: {:.2f}%\".format(gs.best_score_ * 100))\n",
        "print(\"-\"*100)\n",
        "print(\"Parámetros del estimador: \" + str(gs.best_estimator_))\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Predecimos los casos de test para ver el accuracy\n",
        "y_pred_si = gs.best_estimator_.predict(X_test_si)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3-ifogeUZIo"
      },
      "source": [
        "Veamos los resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCgfbFyKUXwr"
      },
      "source": [
        "#Exactitud del modelo\n",
        "print('AUC del modelo: {:.2f} %'.format(metrics.roc_auc_score(y_test_si, y_pred_si)*100))\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Reporte del clasificador\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_si, y_pred_si))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8TSxfiTKWgX"
      },
      "source": [
        "#### **Opción 2**: Sin escalar las variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul8wnQxzKbr1"
      },
      "source": [
        "# Sin escalar las variables\n",
        "X_diabetes_si_se = df_diabetes_si.drop([\"Outcome\"],axis = 1)\n",
        "y_diabetes_si_se = df_diabetes_si[\"Outcome\"]\n",
        "\n",
        "# Dividimos en entrenamiento y prueba\n",
        "X_train_si_se, X_test_si_se, y_train_si_se, y_test_si_se = train_test_split(X_diabetes_si_se, y_diabetes_si_se, test_size=0.3, stratify = y_diabetes_si_se, random_state=42)\n",
        "\n",
        "X_train_si_se.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2izTd1DNQLkd"
      },
      "source": [
        "Ahora probamos el **modelo KNN** sin estandarizar los valores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vub817jYQKql"
      },
      "source": [
        "parametros = {'penalty': ['l2'],\n",
        "               'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "# Realizamos la búsqueda con Bayes Search\n",
        "modeloRL = LogisticRegression()\n",
        "gs_se = BayesSearchCV(modeloRL, parametros, scoring='roc_auc', verbose=0 , n_jobs=-1, cv = 3, random_state=3)\n",
        "gs_se.fit(X_train_si_se, y_train_si_se)\n",
        "\n",
        "# Mostramos los resultados del mejor modelo\n",
        "print(\"-\"*100)\n",
        "print(\"AUC en CV: {:.2f}%\".format(gs_se.best_score_ * 100))\n",
        "print(\"-\"*100)\n",
        "print(\"Parámetros del estimador: \" + str(gs_se.best_estimator_))\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Predecimos los casos de test para ver el accuracy\n",
        "y_pred_si_se = gs_se.best_estimator_.predict(X_test_si_se)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es importante notar que en el dataset donde los datos no fueron escalados, si bien la performance del modelo es similar, el mismo codigo nos esta dando una alerta de que no llego a converger y que escalar los valores ayudaria a la convergencia:\n",
        "\n",
        "```\n",
        "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
        "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
        "\n",
        "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
        "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
        "Please also refer to the documentation for alternative solver options:\n",
        "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
        "  n_iter_i = _check_optimize_result(\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "oLbwWmRrcOrY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewxQ5kHyUoAx"
      },
      "source": [
        "Veamos los resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ldpMmOGUncx"
      },
      "source": [
        "#Exactitud del modelo\n",
        "print('Exactitud (accuracy) del modelo: {:.2f} %'.format(metrics.roc_auc_score(y_test_si_se, y_pred_si_se)*100))\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Reporte del clasificador\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_si_se, y_pred_si_se))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqjHk12qXmUa"
      },
      "source": [
        "### **CONCLUSIÓN FINAL**\n",
        "\n",
        "Pudimos ver que no hay gran influencia del **escalado** en el modelo probado, el cual **incrementó solo 1 puntos porcentuales de AUC Score** cuando los datos fueron escalados.\n",
        "Si bien el escalado no es mandatorio para los modelos de regresion logística a priori, estos ayudan al algoritmo a converger mas rapido asi como tambien agregan \"explicabilidad\" a los Beta, dado que al estar todas las variables en la misma escala, los betas estan expresados en unidades comparables y eso realmente ayuda a entender que variable explicativa tiene mas o menos peso."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con Escalado de Variables"
      ],
      "metadata": {
        "id": "gkE085ZIY6PF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti-NeRge_X-M"
      },
      "source": [
        "pd.DataFrame({'Atributo':X_train.columns,\n",
        "              'importancia':abs(gs.best_estimator_.coef_[0])}).sort_values('importancia', ascending=False).head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sin Escalado de Variables"
      ],
      "metadata": {
        "id": "DiH8jfijY8r6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'Atributo':X_train.columns,\n",
        "              'importancia':abs(gs_se.best_estimator_.coef_[0])}).sort_values('importancia', ascending=False).head(10)"
      ],
      "metadata": {
        "id": "i2vBnUmPYrmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficamos ambas curvas ROC"
      ],
      "metadata": {
        "id": "SP3H7Sf8ZoxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def graficarCurvaRoc( y_pred, model ):\n",
        "  fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred)\n",
        "  auc = metrics.roc_auc_score(y_test, y_pred)\n",
        "  # Graficamos\n",
        "  plt.plot(fpr,tpr,label= model +\" AUC=\"+str(round(auc,4))) #,label= \"AUC=\"+str(auc))\n",
        "  plt.legend(loc=4, fontsize=12)\n",
        "  return auc\n",
        "\n",
        "# Inicializamos los labels del gráfico\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.xlabel('% Not Hazardous', fontsize=14)\n",
        "plt.ylabel('% Hazardous', fontsize=14)\n",
        "\n",
        "# Graficamos la recta del azar\n",
        "it = [i/100 for i in range(100)]\n",
        "plt.plot(it,it,label=\"AZAR AUC=0.5\",color=\"black\")\n",
        "\n",
        "modelos = {'sin-escalar':y_pred_si_se, 'escalando':y_pred_si}\n",
        "for pred in modelos:\n",
        "    auc = graficarCurvaRoc( modelos[pred] , pred )\n",
        "\n",
        "# Agregamos el titulo y configuro el tamaño de letra\n",
        "plt.title(\"Curva ROC\", fontsize=14)\n",
        "plt.tick_params(labelsize=12);\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EYEV4QSfZSwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UZcTyZqNYsFy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}